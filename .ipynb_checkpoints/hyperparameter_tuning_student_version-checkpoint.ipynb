{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning Coding Challenge\n",
    "\n",
    "Â© Explore Data Science Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions to Students\n",
    "- **Do not add or remove cells in this notebook. Do not edit or remove the `### START FUNCTION` or `### END FUNCTION` comments. Do not add any code outside of the functions you are required to edit. Doing any of this will lead to a mark of 0%!**\n",
    "- Answer the questions according to the specifications provided.\n",
    "- Use the given cell in each question to to see if your function matches the expected outputs.\n",
    "- Do not hard-code answers to the questions.\n",
    "- The use of stackoverflow, google, and other online tools are permitted. However, copying fellow student's code is not permissible and is considered a breach of the Honour code below. Doing this will result in a mark of 0%.\n",
    "- Good luck, and may the force be with you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Honour Code\n",
    "\n",
    "I **YOUR NAME**, **YOUR SURNAME**, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the EDSA honour code (https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Hyperparameters have a direct impact on the performance and predictions made by machine learning models. Within this coding challenge, we will strengthen our ability to produce appropriate classification solutions by extending a base model with tuned hyperparameters. \n",
    "\n",
    "<br></br>\n",
    "\n",
    "<div align=\"center\" style=\"width: 600px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/wine.jpg\"\n",
    "     alt=\"Some fine wine for your fine model\"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=600px/>\n",
    "Some fine wine for your fine modeling process. \n",
    "Photo by <a href=\"https://unsplash.com/@hermez777?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\"> Hermes Rivera</a> on Unsplash\n",
    "</div>\n",
    "\n",
    "The structure of this notebook is as follows:\n",
    "\n",
    " - First, we'll load our data to get a view of the predictor and response variables we will be modeling. \n",
    " - We'll then preprocess our data, binarising the target variable and splitting up the data intro train and test sets. \n",
    " - We then model our data using a Support Vector Classifier.\n",
    " - Following this modeling, we define a custom metric as the log-loss in order to evaluate our produced model.\n",
    " - Using this metric, we then take several steps to improve our base model's performance by optimising the hyperparameters of the SVC through a grid search strategy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Let's go ahead and load the usual suspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset \n",
    "\n",
    "For this coding challenge we'll be using the [Wine Quality dataset](https://archive.ics.uci.edu/ml/datasets/wine+quality) from the UCI Machine Learning Repository. The constituents of this dataset are red and white variants of the Portuguese \"Vinho Verde\" wine. \n",
    "\n",
    "This dataset consists of the following variables: \n",
    "\n",
    " - fixed acidity\n",
    " - volatile acidity\n",
    " - citric acid\n",
    " - residual sugar\n",
    " - chlorides\n",
    " - free sulfur dioxide\n",
    " - total sulfur dioxide\n",
    " - density\n",
    " - pH\n",
    " - sulphates\n",
    " - alcohol\n",
    " - quality (score between 0 and 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the data\n",
    "\n",
    "\n",
    "**Note** the feature we will be predicting is quality, i.e. the label is 'quality' using classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/classification_sprint/winequality.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Data Preprocessing\n",
    "\n",
    "We would like to classify the wine according to it's quality using binary classification.\n",
    "Write a function to preprocess the data so we can run it through the classifier. The function should:\n",
    "\n",
    "* Convert the quality for lower quality wines (quality less than or equal to 4) to 0\n",
    "* Convert the quality for higher quality wines (quality greater than or equal to 5) to 1\n",
    "* Split the data into 75% training and 25% testing data\n",
    "* Set random_state to equal 42 for this internal method. \n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take a dataframe\n",
    "* Standardise the features using sklearn's ```StandardScaler```\n",
    "* Convert the quality labels into a binary labels\n",
    "* Should fill nan values with zeros\n",
    "* Should return two `tuples` of the form `(X_train, y_train), (X_test, y_test)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def data_preprocess(df):\n",
    "    # fill nan with 0\n",
    "    df = df.fillna(0)\n",
    "    # convert the quality labels into a binary labels\n",
    "    df[df.columns[-1]] = df[df.columns[-1]].apply(lambda x: 0 if x < 5 else 1)\n",
    "    \n",
    "    # create features and label\n",
    "    y = df[df.columns[-1]].to_numpy()\n",
    "    X = df.drop(df.columns[-1], axis=1)\n",
    "    \n",
    "    # standardize features using standardscaler\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # train, test and split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled,\n",
    "                                                       y,\n",
    "                                                       test_size=0.25,\n",
    "                                                       random_state=42)\n",
    "    \n",
    "    return (X_train, y_train),(X_test, y_test)\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = data_preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "```python\n",
    "(X_train, y_train), (X_test, y_test)= data_preprocess(df)\n",
    "print(X_train[:2])\n",
    "print(y_train[:2])\n",
    "print(X_test[:2])\n",
    "print(y_test[:2])\n",
    "\n",
    "\n",
    "[[-0.57136659  0.07127869 -0.48054096  1.17914161 -0.09303318 -0.79974133\n",
    "   0.0830898  -0.15472329 -0.36573452  0.13010447  0.06101473  0.25842195]\n",
    " [-0.57136659  1.50396711 -0.72301571  0.56008035 -0.63948302 -0.05776881\n",
    "  -0.70572997  0.62379657  0.16787589 -0.86828773 -0.47467813 -0.99931317]]\n",
    "\n",
    "[1 0]\n",
    "\n",
    "[[-0.57136659 -0.15493527 -0.54115965  0.90400327 -0.66050032 -0.31460545\n",
    "   0.53384396  0.03990667 -1.35291379 -0.26925241 -0.34075491  1.18076103]\n",
    " [-0.57136659  0.29749266 -1.20796522  2.8987562  -0.80762143 -0.45729248\n",
    "  -0.19863155 -0.22549783 -1.03274754 -0.7185289  -0.87644778  0.25842195]]\n",
    "\n",
    "[1 1] \n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Model Training\n",
    "\n",
    "Now that you have processed your data, let's jump straight into model fitting. Write a function that should:\n",
    "* Instantiate a `SVC` model.\n",
    "* Train the `SVC` model with default parameters.\n",
    "* Return the trained SVC model. \n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take two numpy `arrays` as input in the form `(X_train, y_train)`.\n",
    "* Should return an sklearn `SVC` model which has a random state of 40 and gamma set to 'auto'.\n",
    "* The returned model should be fitted to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def train_SVC_model(X_train,y_train):\n",
    "    # your code here\n",
    "    model = SVC(random_state=40,gamma='auto')\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = train_SVC_model(X_train,y_train)\n",
    "svc.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_**Expected Outputs:**_\n",
    "\n",
    "```python\n",
    "svc.classes_\n",
    "```\n",
    "```\n",
    "array([0, 1], dtype=int64)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - Model Testing\n",
    "\n",
    "Now that you've trained your model. It's time to test its accuracy, however, we'll be using a custom scoring function for this. Create a function that implements the log loss function:\n",
    "\n",
    "$$\\Large  H(p,q)=  -\\frac{1}{N}\\sum_{i=1}^{N} ylog(\\hat{y}_{i}) + (1- y)log(1 - \\hat{y}_{i})$$\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take two numpy `arrays` as input in the form `y_true` and `y_predicted`.\n",
    "* Should return a `float64` for the log loss value rounded to 7 decimal places.\n",
    "\n",
    "_**Hint:**_ the numpy subtract function can be used to perform a calculation across an array of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def custom_scoring_function(y_true, y_pred):\n",
    "    # your code here\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.maximum(epsilon, y_pred)\n",
    "    y_pred = np.minimum(1-epsilon, y_pred)\n",
    "    \n",
    "    from sklearn.metrics import log_loss\n",
    "    # Evaluate the model using the log loss metric\n",
    "    loss = round(log_loss(y_true, y_pred), 7)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(X_test)\n",
    "print('Log Loss value: ', custom_scoring_function(y_test, y_pred))\n",
    "print('Accuracy: ',round(accuracy_score(y_test,y_pred),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "```python\n",
    "print('Log Loss value: ',custom_scoring_function(y_test,y_pred))\n",
    "print('Accuracy: ',accuracy_score(y_test,y_pred))\n",
    "```\n",
    "\n",
    "> ```\n",
    "Log Loss value:  1.2540518\n",
    "Accuracy:  0.9637\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization\n",
    "\n",
    "### Question 4.1 - Getting model parameters\n",
    "In order to improve the accuracy of our classifier, we have to search for the best possible model (`SVC` in this case) parameters. However, we first have to find out what parameters can be tuned for the given model. Write a function that returns a list of available hyperparameters for a given model. \n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take in an sklearn model (estimator) object.\n",
    "* Should return a list of parameters for the given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def get_model_hyperparams(model):\n",
    "    # your code here\n",
    "    params = model.get_params()\n",
    "    param_names = list(params.keys())\n",
    "    \n",
    "    return param_names\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_hyperparams(svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "\n",
    "```python\n",
    "get_model_hyperparams(SVC)\n",
    "```\n",
    "\n",
    "> ```\n",
    "['C',\n",
    " 'cache_size',\n",
    " 'class_weight',\n",
    " 'coef0',\n",
    " .\n",
    " .\n",
    " .\n",
    " 'shrinking',\n",
    " 'tol',\n",
    " 'verbose']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.2 - Hyperparameter Search\n",
    "The next step is define a set of `SVC` hyperparameters to search over. Write a function that searches for optimal parameters using the given dictionary of hyperparameters:\n",
    "\n",
    "- C_list = [0.1, 1, 10]\n",
    "- {C: 0.1, 1, 10}\n",
    "- gamma_list = [0.01, 0.1, 1]\n",
    "- {gamma: 0.01, 0.1, 1}\n",
    "- D = {'C':[0.1, 1, 10], 'gamma': [0.01, 0.1, 1]}\n",
    "\n",
    "and using `custom_scoring_function` from **Question 3** above as a custom scoring function (_**Hint**_: Have a look at at the `make_scorer` object in sklearn `metrics`).\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should define a parameter grid using the given list of `SVC` hyperparameters\n",
    "* Should return an sklearn `GridSearchCV` object with a cross validation of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def tune_SVC_model(X_train, y_train):\n",
    "    # your code here\n",
    "    scorer = make_scorer(custom_scoring_function)\n",
    "    \n",
    "    # Perform a grid search over the parameter grid\n",
    "    param_grid = {'C':[0.1, 1, 10], 'gamma': [0.01, 0.1, 1]}\n",
    "    grid_search = GridSearchCV(param_grid, cv=5, scoring=scorer)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc_tuned.predict(X_test)\n",
    "print('Log Loss value: ',custom_scoring_function(y_test,y_pred))\n",
    "print('Accuracy: ',round(accuracy_score(y_test,y_pred),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "```python\n",
    "print('Log Loss value: ',custom_scoring_function(y_test,y_pred))\n",
    "print('Accuracy: ',accuracy_score(y_test,y_pred))\n",
    "```\n",
    "\n",
    "> ```\n",
    "Log Loss value:  1.2115421\n",
    "Accuracy:  0.9649\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.3 - Optimal model parameters\n",
    "Write a function that returns the best hyperperameters for a given model (i.e. the `GridSearchCV`). \n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take in an sklearn GridSearchCV object.\n",
    "* Should return a dictionary of optimal parameters for the given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "# function that returns best params\n",
    "def get_best_params(model):\n",
    "    \n",
    "    # your code here\n",
    "    return\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_best_params(svc_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "```python\n",
    "get_best_params(svc_tuned)\n",
    "```\n",
    "\n",
    "> ```\n",
    "{'C': 1, 'gamma': 1}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
